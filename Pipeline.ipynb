{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(row_csv, trainData_csv, testData_csv = None):\n",
    "    \n",
    "    data, numerical_cols, bin_cols, mul_cols = preprocessing(row_csv, trainData_csv, testData_csv)\n",
    "    combined_train_test = feature_extraction(data, numerical_cols, bin_cols, mul_cols)\n",
    "    return combined_train_test[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(row_csv, trainData_csv, testData_csv = None):\n",
    "    \"\"\"\n",
    "        row_csv:           a csv file containing target column index.\n",
    "        trainData_csv:     training dataset, csv file.\n",
    "        testData_csv:      testing dataset, csv file.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # create dataframe\n",
    "    if testData_csv:\n",
    "        test_df = pd.read_csv(testData_csv)\n",
    "    train_df = pd.read_csv(trainData_csv, encoding = \"latin1\")\n",
    "    row = pd.read_csv(row_csv)\n",
    "    target_index = int(row[\"targetIndex\"])\n",
    "    \n",
    "    # get features\n",
    "    features = list(train_df.columns)\n",
    "    \n",
    "    # id column\n",
    "        # code here\n",
    "        #\n",
    "        # try to find the id which contributes little on classification\n",
    "        # drop id \n",
    "        #\n",
    "        \n",
    "    # target column\n",
    "    target = features[target_index]\n",
    "    target_col = train_df[target]\n",
    "    features.remove(target)\n",
    "    train_df.drop([target], axis = 1, inplace = True)\n",
    "    \n",
    "    # combine train and test\n",
    "    combined_train_test = [train_df, test_df] if testData_csv else [train_df]\n",
    "    \n",
    "    # replace spaces with null value\n",
    "    for dataset in combined_train_test:\n",
    "        for feature in features:\n",
    "            dataset[feature] = dataset[feature].replace(\" \", np.nan)\n",
    "    \n",
    "    # if too much nan value, we can drop the feature\n",
    "    for dataset in combined_train_test:\n",
    "        for feature in features:\n",
    "            if dataset[feature].isna().sum()/dataset[feature].count() >= 3:\n",
    "                dataset.drop([feature], axis = 1, inplace = True)\n",
    "                features.remove(feature)\n",
    "    \n",
    "    # numerical columns\n",
    "    numerical_cols = list(train_df.select_dtypes(exclude = \"object\").columns)\n",
    "    numerical_cols = [x for x in numerical_cols if train_df[x].nunique() > 6]\n",
    "    \n",
    "    # categorical columns\n",
    "    categorical_cols = [x for x in features if not x in numerical_cols]\n",
    "    \n",
    "    # binary columns\n",
    "    bin_cols = train_df.nunique()[train_df.nunique() <= 6].keys().tolist()\n",
    "    \n",
    "    # multivalues columns\n",
    "    mul_cols = [x for x in categorical_cols if not x in bin_cols]\n",
    "    \n",
    "    print(\"feature = \", features)\n",
    "    #print(\"catagorical = \", categorical_cols)\n",
    "    #print(\"numerical = \", numerical_cols)\n",
    "    #print(\"binary = \", bin_cols)\n",
    "    #print(\"multivalue = \", mul_cols)\n",
    "    \n",
    "    # fill in missing values\n",
    "    for dataset in combined_train_test:\n",
    "        for feature in numerical_cols:\n",
    "            dataset[feature].fillna(dataset[feature].median(), inplace = True)\n",
    "        \n",
    "        for feature in categorical_cols:\n",
    "            dataset[feature].fillna(dataset[feature].mode()[0], inplace = True)\n",
    "    \n",
    "    # normalization\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    for dataset in combined_train_test:\n",
    "        for feature in numerical_cols:\n",
    "            dataset[feature] = scaler.fit_transform(dataset[feature].values.reshape(-1, 1))\n",
    "    \n",
    "    # label encode\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    encoder = LabelEncoder()\n",
    "    for dataset in combined_train_test:\n",
    "        for feature in bin_cols:\n",
    "            dataset[feature] = encoder.fit_transform(dataset[feature])\n",
    "            \n",
    "    # pack dataset for next step\n",
    "    if testData_csv:\n",
    "        data = [train_df, target_col, test_df]\n",
    "    else:\n",
    "        data = [train_df, target_col]\n",
    "    \n",
    "    return data, numerical_cols, bin_cols, mul_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature =  ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.730108</td>\n",
       "      <td>2</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.565736</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.726220</td>\n",
       "      <td>0</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663861</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.722332</td>\n",
       "      <td>2</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.258337</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.718444</td>\n",
       "      <td>0</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433312</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>113803</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.714556</td>\n",
       "      <td>2</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433312</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>373450</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0    -1.730108       2                            Braund, Mr. Owen Harris   \n",
       "1    -1.726220       0  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2    -1.722332       2                             Heikkinen, Miss. Laina   \n",
       "3    -1.718444       0       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4    -1.714556       2                           Allen, Mr. William Henry   \n",
       "\n",
       "   Sex       Age     SibSp     Parch            Ticket      Fare  Embarked  \n",
       "0    1 -0.565736  0.432793 -0.473674         A/5 21171 -0.502445         2  \n",
       "1    0  0.663861  0.432793 -0.473674          PC 17599  0.786845         0  \n",
       "2    0 -0.258337 -0.474545 -0.473674  STON/O2. 3101282 -0.488854         2  \n",
       "3    0  0.433312  0.432793 -0.473674            113803  0.420730         2  \n",
       "4    1  0.433312 -0.474545 -0.473674            373450 -0.486337         2  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(\"row1.csv\",\"train.csv\",\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature =  ['Area Abbreviation', 'Area Code', 'Area', 'Item Code', 'Item', 'Element', 'Unit', 'latitude', 'longitude', 'Y1961', 'Y1962', 'Y1963', 'Y1964', 'Y1965', 'Y1966', 'Y1967', 'Y1968', 'Y1969', 'Y1970', 'Y1971', 'Y1972', 'Y1973', 'Y1974', 'Y1975', 'Y1976', 'Y1977', 'Y1978', 'Y1979', 'Y1980', 'Y1981', 'Y1982', 'Y1983', 'Y1984', 'Y1985', 'Y1986', 'Y1987', 'Y1988', 'Y1989', 'Y1990', 'Y1991', 'Y1992', 'Y1993', 'Y1994', 'Y1995', 'Y1996', 'Y1997', 'Y1998', 'Y1999', 'Y2000', 'Y2001', 'Y2002', 'Y2003', 'Y2004', 'Y2005', 'Y2006', 'Y2007', 'Y2008', 'Y2009', 'Y2010', 'Y2011', 'Y2012', 'Y2013']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area Abbreviation</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Area</th>\n",
       "      <th>Item Code</th>\n",
       "      <th>Item</th>\n",
       "      <th>Element</th>\n",
       "      <th>Unit</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Y1961</th>\n",
       "      <th>...</th>\n",
       "      <th>Y2004</th>\n",
       "      <th>Y2005</th>\n",
       "      <th>Y2006</th>\n",
       "      <th>Y2007</th>\n",
       "      <th>Y2008</th>\n",
       "      <th>Y2009</th>\n",
       "      <th>Y2010</th>\n",
       "      <th>Y2011</th>\n",
       "      <th>Y2012</th>\n",
       "      <th>Y2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>-1.694187</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>-1.229856</td>\n",
       "      <td>Wheat and products</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.547731</td>\n",
       "      <td>0.786473</td>\n",
       "      <td>1.034979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558353</td>\n",
       "      <td>0.593188</td>\n",
       "      <td>0.626673</td>\n",
       "      <td>0.691995</td>\n",
       "      <td>0.680541</td>\n",
       "      <td>0.725881</td>\n",
       "      <td>0.713496</td>\n",
       "      <td>0.708875</td>\n",
       "      <td>0.702640</td>\n",
       "      <td>0.694641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>-1.694187</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.743697</td>\n",
       "      <td>Rice (Milled Equivalent)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.547731</td>\n",
       "      <td>0.786473</td>\n",
       "      <td>0.011582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012069</td>\n",
       "      <td>-0.007954</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>-0.009658</td>\n",
       "      <td>-0.005534</td>\n",
       "      <td>-0.019354</td>\n",
       "      <td>-0.015933</td>\n",
       "      <td>-0.012738</td>\n",
       "      <td>-0.022416</td>\n",
       "      <td>-0.024695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>-1.694187</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>-1.216430</td>\n",
       "      <td>Barley and products</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.547731</td>\n",
       "      <td>0.786473</td>\n",
       "      <td>-0.051171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084834</td>\n",
       "      <td>-0.049269</td>\n",
       "      <td>-0.045282</td>\n",
       "      <td>-0.045980</td>\n",
       "      <td>-0.052951</td>\n",
       "      <td>-0.025861</td>\n",
       "      <td>-0.038186</td>\n",
       "      <td>-0.059255</td>\n",
       "      <td>-0.032006</td>\n",
       "      <td>-0.034665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>-1.694187</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>-1.216430</td>\n",
       "      <td>Barley and products</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.547731</td>\n",
       "      <td>0.786473</td>\n",
       "      <td>0.043252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059235</td>\n",
       "      <td>-0.087421</td>\n",
       "      <td>-0.087840</td>\n",
       "      <td>-0.086653</td>\n",
       "      <td>-0.083589</td>\n",
       "      <td>-0.084424</td>\n",
       "      <td>-0.082866</td>\n",
       "      <td>-0.081577</td>\n",
       "      <td>-0.079792</td>\n",
       "      <td>-0.078247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>-1.694187</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>-1.209717</td>\n",
       "      <td>Maize and products</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.547731</td>\n",
       "      <td>0.786473</td>\n",
       "      <td>0.027417</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072337</td>\n",
       "      <td>-0.054804</td>\n",
       "      <td>-0.050943</td>\n",
       "      <td>-0.048628</td>\n",
       "      <td>-0.049850</td>\n",
       "      <td>-0.059119</td>\n",
       "      <td>-0.062190</td>\n",
       "      <td>-0.061300</td>\n",
       "      <td>-0.059620</td>\n",
       "      <td>-0.060396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Area Abbreviation  Area Code         Area  Item Code  \\\n",
       "0               AFG  -1.694187  Afghanistan  -1.229856   \n",
       "1               AFG  -1.694187  Afghanistan   0.743697   \n",
       "2               AFG  -1.694187  Afghanistan  -1.216430   \n",
       "3               AFG  -1.694187  Afghanistan  -1.216430   \n",
       "4               AFG  -1.694187  Afghanistan  -1.209717   \n",
       "\n",
       "                       Item  Element  Unit  latitude  longitude     Y1961  \\\n",
       "0        Wheat and products        1     0  0.547731   0.786473  1.034979   \n",
       "1  Rice (Milled Equivalent)        1     0  0.547731   0.786473  0.011582   \n",
       "2       Barley and products        0     0  0.547731   0.786473 -0.051171   \n",
       "3       Barley and products        1     0  0.547731   0.786473  0.043252   \n",
       "4        Maize and products        0     0  0.547731   0.786473  0.027417   \n",
       "\n",
       "   ...     Y2004     Y2005     Y2006     Y2007     Y2008     Y2009     Y2010  \\\n",
       "0  ...  0.558353  0.593188  0.626673  0.691995  0.680541  0.725881  0.713496   \n",
       "1  ... -0.012069 -0.007954  0.010161 -0.009658 -0.005534 -0.019354 -0.015933   \n",
       "2  ... -0.084834 -0.049269 -0.045282 -0.045980 -0.052951 -0.025861 -0.038186   \n",
       "3  ... -0.059235 -0.087421 -0.087840 -0.086653 -0.083589 -0.084424 -0.082866   \n",
       "4  ... -0.072337 -0.054804 -0.050943 -0.048628 -0.049850 -0.059119 -0.062190   \n",
       "\n",
       "      Y2011     Y2012     Y2013  \n",
       "0  0.708875  0.702640  0.694641  \n",
       "1 -0.012738 -0.022416 -0.024695  \n",
       "2 -0.059255 -0.032006 -0.034665  \n",
       "3 -0.081577 -0.079792 -0.078247  \n",
       "4 -0.061300 -0.059620 -0.060396  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(\"row2.csv\",\"FAO.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(data, numerical_cols, bin_cols, mul_cols):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # unpack data\n",
    "    if len(data) == 3:\n",
    "        train_df, test_df = data[0], data[2]\n",
    "        combined_train_test = [train_df, test_df]\n",
    "        target_col = data[1]\n",
    "    else:\n",
    "        train_df, target_col = data[0], data[1]\n",
    "        combined_train_test = [train_df]\n",
    "    numerical_cols = numerical_cols\n",
    "    bin_cols, mul_cols = bin_cols, mul_cols\n",
    "    \n",
    "    #\n",
    "    \n",
    "    \n",
    "    \n",
    "    return combined_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def feature_selection():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def estimation():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def postprocessing():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
